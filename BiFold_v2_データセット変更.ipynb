{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaQweLPcssJh"
      },
      "source": [
        "# Bifold_v2\n",
        "- automodel_nameをGoogle siglip base patchの部分を新しいモデルに変更\n",
        "- Colab上での表示設定の変更"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pAFZtO6_05b"
      },
      "source": [
        "## GitHubをクローンしてimportできるか"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l57TwjsUUAth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46121dad-a85c-4405-a108-57dea2bbd785"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ShT559YsoJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea379570-41e8-4c6e-e20f-d359a19ed5e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bifold'...\n",
            "remote: Enumerating objects: 948, done.\u001b[K\n",
            "remote: Counting objects: 100% (948/948), done.\u001b[K\n",
            "remote: Compressing objects: 100% (692/692), done.\u001b[K\n",
            "remote: Total 948 (delta 227), reused 943 (delta 225), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (948/948), 19.42 MiB | 18.35 MiB/s, done.\n",
            "Resolving deltas: 100% (227/227), done.\n",
            "/content/bifold\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/syarasyoujyu/bifold.git\n",
        "%cd bifold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3sAN7-ER0N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31d7d274-31fb-43cd-9237-28c796019d45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/bifold\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hydra-core (from bifold==1.0)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from bifold==1.0) (2.9.0+cu128)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from bifold==1.0) (0.24.0+cu128)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.12/dist-packages (from bifold==1.0) (2.37.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from bifold==1.0) (4.67.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from bifold==1.0) (3.10.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from bifold==1.0) (5.24.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from bifold==1.0) (1.16.3)\n",
            "Collecting ftfy (from bifold==1.0)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from bifold==1.0) (2025.11.3)\n",
            "Collecting open3d (from bifold==1.0)\n",
            "  Downloading open3d-0.19.0-cp312-cp312-manylinux_2_31_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (from bifold==1.0) (0.18.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from bifold==1.0) (0.2.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from bifold==1.0) (0.8.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from bifold==1.0) (5.0.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (from bifold==1.0) (1.0.24)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from bifold==1.0) (4.13.0.92)\n",
            "Collecting torchmetrics (from bifold==1.0)\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting trimesh (from bifold==1.0)\n",
            "  Downloading trimesh-4.11.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from bifold==1.0) (0.24.2)\n",
            "Collecting zarr (from bifold==1.0)\n",
            "  Downloading zarr-3.1.5-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->bifold==1.0) (0.5.3)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.12/dist-packages (from hydra-core->bifold==1.0) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core->bifold==1.0) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from hydra-core->bifold==1.0) (26.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from imageio->bifold==1.0) (2.0.2)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio->bifold==1.0) (11.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bifold==1.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bifold==1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bifold==1.0) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bifold==1.0) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bifold==1.0) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bifold==1.0) (2.9.0.post0)\n",
            "Collecting dash>=2.6.0 (from open3d->bifold==1.0)\n",
            "  Downloading dash-4.0.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: werkzeug>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from open3d->bifold==1.0) (3.1.5)\n",
            "Requirement already satisfied: flask>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from open3d->bifold==1.0) (3.1.2)\n",
            "Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.12/dist-packages (from open3d->bifold==1.0) (5.10.4)\n",
            "Collecting configargparse (from open3d->bifold==1.0)\n",
            "  Downloading configargparse-1.7.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting ipywidgets>=8.0.4 (from open3d->bifold==1.0)\n",
            "  Downloading ipywidgets-8.1.8-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting addict (from open3d->bifold==1.0)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.12/dist-packages (from open3d->bifold==1.0) (2.2.2)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.12/dist-packages (from open3d->bifold==1.0) (6.0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.12/dist-packages (from open3d->bifold==1.0) (1.6.1)\n",
            "Collecting pyquaternion (from open3d->bifold==1.0)\n",
            "  Downloading pyquaternion-0.9.9-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft->bifold==1.0) (5.9.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft->bifold==1.0) (1.12.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft->bifold==1.0) (0.7.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from peft->bifold==1.0) (1.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->bifold==1.0) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->bifold==1.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->bifold==1.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->bifold==1.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->bifold==1.0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->bifold==1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->bifold==1.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->bifold==1.0) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->bifold==1.0) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->bifold==1.0) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->bifold==1.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->bifold==1.0) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch->bifold==1.0) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch->bifold==1.0) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch->bifold==1.0) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->bifold==1.0) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->bifold==1.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->bifold==1.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->bifold==1.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->bifold==1.0) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->bifold==1.0) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch->bifold==1.0) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->bifold==1.0) (3.5.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->bifold==1.0) (9.1.3)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics->bifold==1.0)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->bifold==1.0) (0.22.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers->bifold==1.0) (0.21.1)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb->bifold==1.0) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->bifold==1.0) (3.1.46)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb->bifold==1.0) (4.5.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb->bifold==1.0) (5.29.6)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb->bifold==1.0) (2.12.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->bifold==1.0) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->bifold==1.0) (2.52.0)\n",
            "Collecting donfig>=0.8 (from zarr->bifold==1.0)\n",
            "  Downloading donfig-0.8.1.post1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: google-crc32c>=1.5 in /usr/local/lib/python3.12/dist-packages (from zarr->bifold==1.0) (1.8.0)\n",
            "Collecting numcodecs>=0.14 (from zarr->bifold==1.0)\n",
            "  Downloading numcodecs-0.16.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/dist-packages (from dash>=2.6.0->open3d->bifold==1.0) (8.7.1)\n",
            "Collecting retrying (from dash>=2.6.0->open3d->bifold==1.0)\n",
            "  Downloading retrying-1.4.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from dash>=2.6.0->open3d->bifold==1.0) (1.6.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask>=3.0.0->open3d->bifold==1.0) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask>=3.0.0->open3d->bifold==1.0) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask>=3.0.0->open3d->bifold==1.0) (3.0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->bifold==1.0) (4.0.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft->bifold==1.0) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft->bifold==1.0) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft->bifold==1.0) (1.5.4)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.0.4->open3d->bifold==1.0)\n",
            "  Downloading comm-0.2.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=8.0.4->open3d->bifold==1.0) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=8.0.4->open3d->bifold==1.0) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.14 (from ipywidgets>=8.0.4->open3d->bifold==1.0)\n",
            "  Downloading widgetsnbextension-4.0.15-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=8.0.4->open3d->bifold==1.0) (3.0.16)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.7.0->open3d->bifold==1.0) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.7.0->open3d->bifold==1.0) (4.26.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.7.0->open3d->bifold==1.0) (5.9.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0->open3d->bifold==1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0->open3d->bifold==1.0) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->bifold==1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->bifold==1.0) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->bifold==1.0) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->bifold==1.0) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->bifold==1.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->bifold==1.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->bifold==1.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->bifold==1.0) (2026.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21->open3d->bifold==1.0) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21->open3d->bifold==1.0) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->bifold==1.0) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->bifold==1.0) (5.0.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.25.0->peft->bifold==1.0) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.25.0->peft->bifold==1.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub>=0.25.0->peft->bifold==1.0) (0.16.0)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d->bifold==1.0)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d->bifold==1.0) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d->bifold==1.0) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d->bifold==1.0) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d->bifold==1.0) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d->bifold==1.0) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d->bifold==1.0) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d->bifold==1.0) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d->bifold==1.0) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d->bifold==1.0) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d->bifold==1.0) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d->bifold==1.0) (0.30.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata->dash>=2.6.0->open3d->bifold==1.0) (3.23.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d->bifold==1.0) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d->bifold==1.0) (0.7.0)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading open3d-0.19.0-cp312-cp312-manylinux_2_31_x86_64.whl (447.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.7/447.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trimesh-4.11.2-py3-none-any.whl (740 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m740.3/740.3 kB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zarr-3.1.5-py3-none-any.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.1/284.1 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash-4.0.0-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m146.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading donfig-0.8.1.post1-py3-none-any.whl (21 kB)\n",
            "Downloading ipywidgets-8.1.8-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading numcodecs-0.16.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (9.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m147.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading configargparse-1.7.1-py3-none-any.whl (25 kB)\n",
            "Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
            "Downloading comm-0.2.3-py3-none-any.whl (7.3 kB)\n",
            "Downloading widgetsnbextension-4.0.15-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.4.2-py3-none-any.whl (10 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: bifold\n",
            "  Building wheel for bifold (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bifold: filename=bifold-1.0-py3-none-any.whl size=10880 sha256=73e8dcdba58281c3011ae752a91a4088420cfe08f2a1c041a72f1438d41d8ffd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1uy0kmuc/wheels/fc/12/d0/ea5002956fa9d516c6a2ae5fce0945b19c08cc8d87ef3edc04\n",
            "Successfully built bifold\n",
            "Installing collected packages: addict, widgetsnbextension, trimesh, retrying, pyquaternion, numcodecs, lightning-utilities, jedi, ftfy, donfig, configargparse, comm, zarr, hydra-core, ipywidgets, dash, torchmetrics, open3d, bifold\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed addict-2.4.0 bifold-1.0 comm-0.2.3 configargparse-1.7.1 dash-4.0.0 donfig-0.8.1.post1 ftfy-6.3.1 hydra-core-1.3.2 ipywidgets-8.1.8 jedi-0.19.2 lightning-utilities-0.15.2 numcodecs-0.16.5 open3d-0.19.0 pyquaternion-0.9.9 retrying-1.4.2 torchmetrics-1.8.2 trimesh-4.11.2 widgetsnbextension-4.0.15 zarr-3.1.5\n"
          ]
        }
      ],
      "source": [
        "!pip install .\n",
        "#!pip install pyflex:こっちのpyfllexとは違うっぽかった"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDd4xwgQ59lW"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"HF_TOKEN\"]=userdata.get('HF_TOKEN')\n",
        "os.environ[\"WANDB_API_KEY\"]=userdata.get('WANDB_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gVN4eDC9pIz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4571f281-f20c-4556-d29c-caad2ed64b4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "利用可能なCPUコア数: 12\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(f\"利用可能なCPUコア数: {os.cpu_count()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/bifold/bifold/__main__.py\n",
        "\n",
        "import os\n",
        "import random\n",
        "from typing import Dict, Optional, Tuple\n",
        "\n",
        "import hydra\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import sys\n",
        "import wandb\n",
        "import yaml\n",
        "from hydra.core.hydra_config import HydraConfig\n",
        "from omegaconf import DictConfig, OmegaConf\n",
        "from torchvision.transforms import v2\n",
        "from tqdm import tqdm      # 表示の変更\n",
        "\n",
        "from .data import Datasets\n",
        "from .losses import Losses\n",
        "from .metrics import Metrics\n",
        "from .models import Models\n",
        "from .optim import Optimizers, Schedulers\n",
        "from .utils.visualization import save_predictions, visualize_action\n",
        "\n",
        "\n",
        "@hydra.main(version_base=None, config_path=\"conf\", config_name=\"config\")\n",
        "def main(cfg: DictConfig):\n",
        "    print(os.getcwd())\n",
        "    with open(\"config.yaml\", \"w\") as f:\n",
        "        OmegaConf.save(cfg, f)\n",
        "\n",
        "    trainer = Trainer(cfg)\n",
        "\n",
        "    if not cfg.eval_only:\n",
        "        trainer.prepare_train()\n",
        "        trainer.train()\n",
        "    trainer.eval()\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, cfg):\n",
        "        self.device = (\n",
        "            torch.device(\"cuda\")\n",
        "            if torch.cuda.is_available() and not cfg.use_cpu\n",
        "            else torch.device(\"cpu\")\n",
        "        )\n",
        "\n",
        "        if cfg.use_wandb and not cfg.eval_only and not cfg.debug:\n",
        "            self.writer = wandb.init(\n",
        "                project=\"WM_Final_v2\",\n",
        "                entity='kazuma_tsuboi',\n",
        "                group=cfg.train_dataset.name,\n",
        "                name=\"+\".join(HydraConfig.get().overrides.task),\n",
        "                resume=\"allow\",\n",
        "            )\n",
        "            wandb.config = OmegaConf.to_container(cfg, resolve=True, throw_on_missing=True)\n",
        "        else:\n",
        "            self.writer = None\n",
        "\n",
        "        self.cfg = cfg\n",
        "\n",
        "        self.seed_randomness()\n",
        "\n",
        "        self.model = Models.get_by_name(self.cfg.model, device=self.device).to(self.device)\n",
        "\n",
        "        self.train_dataloader, self.test_dataloader, self.input_processor = (\n",
        "            Datasets.get_dataloaders(self.cfg)\n",
        "        )\n",
        "        self.metrics = Metrics(self.cfg.metrics)\n",
        "\n",
        "    def train(self):\n",
        "        if self.start_epoch < self.cfg.epochs:\n",
        "            for epoch in tqdm(list(range(self.start_epoch, self.cfg.epochs)), desc=\"Train\", leave = False, ncols=75, file=sys.stdout, position=0):   #leave=False\n",
        "                self.train_epoch(epoch)\n",
        "                if self.cfg.eval_epochs and (epoch + 1) % self.cfg.eval_epochs == 0:\n",
        "                    has_improved, _ = self.eval_epoch(epoch)\n",
        "                    if has_improved:\n",
        "                        self.save_model(epoch, is_best=True)\n",
        "                if self.cfg.save_epochs and (epoch + 1) % self.cfg.save_epochs == 0:\n",
        "                    self.save_model(epoch)\n",
        "\n",
        "            epoch = self.cfg.epochs - 1\n",
        "            self.save_model(epoch)\n",
        "\n",
        "    def eval(self):\n",
        "        self.load_model(load_best=self.cfg.load_best)\n",
        "        eval_file = f\"eval_{self.cfg.test_dataset.name}.yaml\"\n",
        "        _, metric_dict = self.eval_epoch()\n",
        "        for k, val in metric_dict.items():\n",
        "            if isinstance(val, dict):\n",
        "                for sub_k, sub_val in val.items():\n",
        "                    print(f\"{k} {sub_k}:\\t{sub_val:.2f}\")\n",
        "            else:\n",
        "                print(f\"{k}:\\t{val:.2f}\")\n",
        "\n",
        "        if os.path.isfile(eval_file):\n",
        "            print(\"Found YAML file\")\n",
        "            with open(eval_file, \"r\") as f:\n",
        "                old_results = yaml.load(f, Loader=yaml.Loader)\n",
        "            for k, val in old_results.items():\n",
        "                if k not in metric_dict:\n",
        "                    metric_dict[k] = val\n",
        "                else:\n",
        "                    if val != metric_dict[k]:\n",
        "                        print(f\"Old value for {k} = {val} ; New value {metric_dict[k]}\")\n",
        "        with open(eval_file, \"w\") as f:\n",
        "            yaml.dump(metric_dict, f)\n",
        "\n",
        "    def seed_randomness(self):\n",
        "        random.seed(self.cfg.seed)\n",
        "        np.random.seed(self.cfg.seed)\n",
        "        torch.manual_seed(self.cfg.seed)\n",
        "        torch.cuda.manual_seed_all(self.cfg.seed)\n",
        "\n",
        "    def prepare_train(self):\n",
        "        params_non_frozen = filter(lambda p: p.requires_grad, self.model.parameters())\n",
        "        self.loss_fn = Losses.get_by_name(cfg=self.cfg.loss)\n",
        "        self.optimizer = Optimizers.get_by_name(cfg=self.cfg.optim, params=params_non_frozen)\n",
        "        assert self.train_dataloader is not None\n",
        "        self.scheduler = Schedulers.get_by_name(\n",
        "            cfg=self.cfg.scheduler,\n",
        "            optimizer=self.optimizer,\n",
        "            max_iters=len(self.train_dataloader) * self.cfg.epochs,\n",
        "        )\n",
        "        self.load_model()\n",
        "\n",
        "    def train_epoch(self, epoch=None):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        pbar = tqdm(self.train_dataloader, desc=f\"Train Epoch:{epoch}\", leave=False, ncols=75, file=sys.stdout, position=0)     # leave=False\n",
        "        for i, sample in enumerate(pbar):\n",
        "            sample = self.move_sample_to_device(sample)\n",
        "\n",
        "            # Visualize inputs to model\n",
        "            if self.cfg.debug and self.cfg.visualize_model_inputs:\n",
        "                self.visualize_model_inputs(sample)\n",
        "\n",
        "            output = self.model(sample)\n",
        "\n",
        "            loss, intermediate_losses = self.loss_fn(output, sample)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            assert loss is not None\n",
        "            loss.backward()\n",
        "\n",
        "            if self.cfg.debug:\n",
        "                for name, param in self.model.named_parameters():\n",
        "                    if param.requires_grad and param.grad is None:\n",
        "                        raise ValueError(f\"Parameter {name} might not have gradient attached!\")\n",
        "\n",
        "            if self.cfg.gradient_clip is not None:\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.cfg.gradient_clip)\n",
        "            self.optimizer.step()\n",
        "            if self.scheduler is not None:\n",
        "                self.scheduler.step()\n",
        "\n",
        "            if self.writer:\n",
        "                self.writer.log({\"loss\": loss, \"epoch\": epoch})\n",
        "                for k, val in intermediate_losses.items():\n",
        "                    self.writer.log({k: val})\n",
        "                for j, param_group in enumerate(self.optimizer.param_groups):\n",
        "                    self.writer.log({f\"lr_{j}\": param_group[\"lr\"]})\n",
        "\n",
        "            assert loss is not None\n",
        "            total_loss += loss.item()\n",
        "            # pbar.set_description(\"Training loss:{}\".format(total_loss / (i + 1)))\n",
        "\n",
        "    def eval_epoch(self, epoch=None) -> Tuple[Optional[bool], Dict[str, torch.Tensor]]:\n",
        "        self.model.eval()\n",
        "        has_improved = None\n",
        "        if epoch is not None or self.cfg.simulator is None:\n",
        "            # During training or in testing if simulator is not specified\n",
        "            has_improved, metric_dict = self.eval_epoch_pixel(epoch)\n",
        "        elif self.cfg.simulator == \"softgym\":\n",
        "            if self.cfg.test_dataset.is_bimanual:\n",
        "                metric_dict = self.eval_epoch_softgym_bimanual(epoch)\n",
        "            else:\n",
        "                metric_dict = self.eval_epoch_softgym_single(epoch)\n",
        "        else:\n",
        "            raise ValueError(f\"Simulator {self.cfg.simulator} not supported\")\n",
        "\n",
        "        if self.writer:\n",
        "            for k, val in metric_dict.items():\n",
        "                self.writer.log({k: val})\n",
        "\n",
        "        if epoch is not None:\n",
        "            assert (\n",
        "                has_improved is not None\n",
        "            ), \"has_improved boolean must be specified during training\"\n",
        "        return has_improved, metric_dict\n",
        "\n",
        "    def eval_epoch_pixel(self, epoch):\n",
        "        self.metrics.reset()\n",
        "        num_samples = 0\n",
        "        for sample in tqdm(self.test_dataloader, desc=f\"Evaluate Epoch: {epoch}\", leave=False, ncols=75, file=sys.stdout, position=0):     # leave=False\n",
        "            sample = self.move_sample_to_device(sample)\n",
        "\n",
        "            # Pick and place prediction\n",
        "            ret_get_action = self.model.get_action(sample, return_raw_output=True)\n",
        "            assert isinstance(ret_get_action, Tuple)\n",
        "            action, raw_output = ret_get_action\n",
        "\n",
        "            if any(\"pick\" in k for k in sample.keys()):\n",
        "                # If samples are available\n",
        "                self.metrics(action=action, sample=sample, raw_output=raw_output)\n",
        "\n",
        "            if self.cfg.visualize_predictions:\n",
        "                out_folder = (\n",
        "                    os.path.join(\n",
        "                        \"eval_background\",\n",
        "                        self.cfg.test_dataset.name,\n",
        "                        \"pixel_metrics\",\n",
        "                        \"best\" if self.cfg.load_best else \"last\",\n",
        "                    )\n",
        "                    if epoch is None\n",
        "                    else os.path.join(\"eval\", \"pixel_metrics\", f\"epoch_{epoch}\")\n",
        "                )\n",
        "                visualizations = visualize_action(sample, action)\n",
        "                for j in range(len(visualizations)):\n",
        "                    kwargs = {\n",
        "                        \"rgb\": sample[\"raw_rgb\"][j].cpu().numpy(),\n",
        "                        \"depth\": sample[\"depth\"][j].squeeze().cpu().numpy(),\n",
        "                        \"viz\": visualizations[j],\n",
        "                    }\n",
        "                    if raw_output is not None:\n",
        "                        for k, val in raw_output.items():\n",
        "                            if \"heatmap\" in k:\n",
        "                                kwargs[k] = val[j]\n",
        "                    save_predictions(\n",
        "                        out_folder=out_folder,\n",
        "                        out_file_name=f\"{num_samples}_{sample['raw_instruction'][j]}.png\",\n",
        "                        **kwargs,\n",
        "                    )\n",
        "                    num_samples += 1\n",
        "\n",
        "        has_improved, metric_dict = self.metrics.summary()\n",
        "        if self.writer:\n",
        "            for k, val in metric_dict.items():\n",
        "                self.writer.log({k: val})\n",
        "\n",
        "        return has_improved, metric_dict\n",
        "\n",
        "    def eval_epoch_softgym_single(self, epoch):\n",
        "        from .env.softgym_evaluator import SoftgymSingleEvaluator\n",
        "\n",
        "        evaluator = SoftgymSingleEvaluator(\n",
        "            cfg=self.cfg,\n",
        "            model=self.model,\n",
        "            processor=self.input_processor,\n",
        "        )\n",
        "        for task in [\n",
        "            \"CornerFold\",\n",
        "            \"TriangleFold\",\n",
        "            \"StraightFold\",\n",
        "            \"TshirtFold\",\n",
        "            \"TrousersFold\",\n",
        "        ]:\n",
        "            evaluator.evaluate(num_evals=self.cfg.num_evals, task=task)\n",
        "        evaluator.close()\n",
        "\n",
        "        return evaluator.summary()\n",
        "\n",
        "    def eval_epoch_softgym_bimanual(self, epoch):\n",
        "        from .env.softgym_evaluator import SoftgymBimanualEvaluator\n",
        "\n",
        "        evaluator = SoftgymBimanualEvaluator(\n",
        "            self.cfg, model=self.model, processor=self.input_processor\n",
        "        )\n",
        "        for i, sample in enumerate(tqdm(self.test_dataloader, desc=\"Evaluating with SoftGym\", leave = False, ncols=75, file=sys.stdout, position=0)):\n",
        "            evaluator.evaluate(sample)\n",
        "        evaluator.close()\n",
        "\n",
        "        return evaluator.summary()\n",
        "\n",
        "    def load_model(self, load_best=False):\n",
        "        if load_best and os.path.isfile(os.path.join(\"checkpoints\", \"best.pth\")):\n",
        "            checkpoint_file = os.path.join(\"checkpoints\", \"best.pth\")\n",
        "        elif os.path.isfile(os.path.join(\"checkpoints\", \"last.pth\")):\n",
        "            checkpoint_file = os.path.join(\"checkpoints\", \"last.pth\")\n",
        "        else:\n",
        "            if self.cfg.eval_only and not self.cfg.debug:\n",
        "                raise FileNotFoundError(\"Cannot evaluate with untrained model\")\n",
        "            self.start_epoch = 0\n",
        "            return\n",
        "\n",
        "        checkpoint = torch.load(checkpoint_file, map_location=self.device, weights_only=False)\n",
        "        self.start_epoch = checkpoint[\"epoch\"]\n",
        "        random.setstate(checkpoint[\"random_states\"][0])\n",
        "        np.random.set_state(checkpoint[\"random_states\"][1])\n",
        "        torch.set_rng_state(checkpoint[\"random_states\"][2].cpu())\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.set_rng_state(checkpoint[\"random_states\"][3].cpu())\n",
        "\n",
        "        self.model.load_state_dict(checkpoint[\"model\"])\n",
        "\n",
        "        if not self.cfg.eval_only:\n",
        "            self.optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "            if self.scheduler is not None and \"scheduler\" in checkpoint:\n",
        "                self.scheduler.load_state_dict(checkpoint[\"scheduler\"])\n",
        "\n",
        "            if \"best_eval\" in checkpoint:\n",
        "                self.metrics.best_eval = checkpoint[\"best_eval\"]\n",
        "\n",
        "        print(f\"Loaded model from checkpoint {checkpoint_file}\")\n",
        "\n",
        "    def save_model(self, epoch, is_best=False):\n",
        "        os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "        if is_best:\n",
        "            model_path = os.path.join(\"checkpoints\", \"best.pth\")\n",
        "        else:\n",
        "            model_path = os.path.join(\"checkpoints\", \"last.pth\")\n",
        "        state_dict = {\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"random_states\": (\n",
        "                random.getstate(),\n",
        "                np.random.get_state(),\n",
        "                torch.get_rng_state(),\n",
        "                (torch.cuda.get_rng_state() if torch.cuda.is_available() else None),\n",
        "            ),\n",
        "            \"model\": self.model.state_dict(),\n",
        "            \"optimizer\": self.optimizer.state_dict(),\n",
        "        }\n",
        "        if self.scheduler is not None:\n",
        "            state_dict[\"scheduler\"] = self.scheduler.state_dict()\n",
        "        if self.metrics.best_eval is not None:\n",
        "            state_dict[\"best_eval\"] = self.metrics.best_eval\n",
        "        torch.save(state_dict, model_path)\n",
        "\n",
        "    def move_sample_to_device(self, sample):\n",
        "        # Move all inputs to device\n",
        "        for k, val in sample.items():\n",
        "            if isinstance(val, torch.Tensor) or k == \"graph\":\n",
        "                sample[k] = val.to(self.device)\n",
        "        return sample\n",
        "\n",
        "    def visualize_model_inputs(self, sample):\n",
        "        input_visualizations = {}\n",
        "        if self.writer is None:\n",
        "            fig, axes = plt.subplots(ncols=4, nrows=3)\n",
        "            flat_axes = axes.flat\n",
        "            i = 0\n",
        "        else:\n",
        "            fig, flat_axes, i = None, None, None\n",
        "\n",
        "        for k, val in sample.items():\n",
        "            if any(subk in k for subk in [\"rgb\", \"depth\", \"heatmap\"]):\n",
        "                if \"rgb\" in k:\n",
        "                    transform = v2.Compose([\n",
        "                        v2.Normalize(\n",
        "                            (0.0, 0.0, 0.0),\n",
        "                            (\n",
        "                                1 / 0.26862954,\n",
        "                                1 / 0.26130258,\n",
        "                                1 / 0.27577711,\n",
        "                            ),\n",
        "                        ),\n",
        "                        v2.Normalize(\n",
        "                            (-0.48145466, -0.4578275, -0.40821073),\n",
        "                            (1.0, 1.0, 1.0),\n",
        "                        ),\n",
        "                        v2.ToPILImage(),\n",
        "                    ])\n",
        "                else:\n",
        "                    transform = v2.ToPILImage()\n",
        "\n",
        "                if len(val.shape) > 2:\n",
        "                    if len(val.shape) < 5:\n",
        "                        imgs = [transform(val[0])]\n",
        "                        names = [k]\n",
        "                    else:\n",
        "                        imgs = [transform(v) for v in val[0]]\n",
        "                        names = [f\"{k}_{i}\" for i in range(len(imgs))]\n",
        "\n",
        "                    for img, name in zip(imgs, names):\n",
        "                        if self.writer:\n",
        "                            input_visualizations[name] = wandb.Image(\n",
        "                                img,\n",
        "                                caption=sample[\"raw_instruction\"][0],\n",
        "                            )\n",
        "                        else:\n",
        "                            assert flat_axes is not None\n",
        "                            assert i is not None\n",
        "                            flat_axes[i].imshow(img)\n",
        "                            if k == \"depth\":\n",
        "                                for k_in, val_in in sample.items():\n",
        "                                    if \"heatmap\" in k_in and len(val_in[0].shape) > 1:\n",
        "                                        flat_axes[i].imshow(transform(val_in[0]), alpha=0.5)\n",
        "                            flat_axes[i].set_title(name)\n",
        "                            i += 1\n",
        "\n",
        "        if self.writer:\n",
        "            self.writer.log(input_visualizations)\n",
        "        else:\n",
        "            assert fig is not None\n",
        "            fig.suptitle(sample[\"raw_instruction\"][0])\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUNj4pAKSE8G",
        "outputId": "4be2fb55-ba0e-4ed4-a422-98e88708f20b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/bifold/bifold/__main__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDteCeV_Trs8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad4eaaa5-1912-4828-84a2-20da7b3509dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/bifold/bifold/conf/config.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/bifold/bifold/conf/config.yaml\n",
        "---\n",
        "defaults:\n",
        "  - _self_\n",
        "  - model: siglip_sequential\n",
        "  - dataset@train_dataset: single_sequential\n",
        "  - dataset@test_dataset: single_sequential   # 変更\n",
        "  - processor: default\n",
        "  - loss: bce_gaussmap\n",
        "  - optim: adam\n",
        "  - scheduler: linear_warmup\n",
        "  - override hydra/hydra_logging: disabled\n",
        "seed: 3407\n",
        "eval_only: false\n",
        "eval_epochs: 1  # 毎エポック評価\n",
        "save_epochs: 1\n",
        "load_best: true\n",
        "use_wandb: true    # オン\n",
        "num_workers: 8\n",
        "batch_size: 8\n",
        "gradient_clip: null\n",
        "test_batch_size: 8\n",
        "epochs: 30 #num of epoch to train, 30でも十分小さくなっている\n",
        "debug: false\n",
        "num_evals: 5 # only used in simulator-only evaluation\n",
        "metrics:\n",
        "  computed_metrics: [kp_mse, ap_5, ap_10, ap_20, ap_50, iou, quantile_prob]\n",
        "  tracked_metric: kp_mse\n",
        "use_cpu: false\n",
        "simulator: softgym\n",
        "dataset_root: /content/drive/MyDrive/東大松尾研究室/7_Thursday_WM_世界モデル/最終課題研究/bifold_datasets/datasets   # ショートカットにする\n",
        "softgym_cache: ${dataset_root}/tsuboi/softgym_cache\n",
        "visualize_model_inputs: false\n",
        "visualize_predictions: false\n",
        "consecutive: false\n",
        "hydra:\n",
        "  output_subdir:\n",
        "  run:\n",
        "    dir: /content/drive/MyDrive/東大松尾研究室/7_Thursday_WM_世界モデル/最終課題研究/tsuboi/results_v2\n",
        "  job:\n",
        "    chdir: true\n",
        "    config:\n",
        "      override_dirname:\n",
        "        exclude_keys:\n",
        "          - seed\n",
        "          - simulator\n",
        "          - use_wandb\n",
        "          - eval_only\n",
        "          - eval_epochs\n",
        "          - save_epochs\n",
        "          - dataset\n",
        "          - dataset_root\n",
        "          - num_evals\n",
        "          - softgym_task\n",
        "          - softgym_cache\n",
        "          - visualize_attention\n",
        "          - visualize_actions\n",
        "          - num_workers\n",
        "          - load_best\n",
        "          - test_batch_size\n",
        "          - visualize_predictions\n",
        "          - use_cpu\n",
        "          - debug"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/bifold/bifold/conf/model/siglip_sequential.yaml\n",
        "---\n",
        "name: siglip_sequential\n",
        "image_size: ${train_dataset.image_size}\n",
        "is_bimanual: ${train_dataset.is_bimanual}\n",
        "patch_size: 16\n",
        "automodel_name: google/siglip2-base-patch${model.patch_size}-${model.image_size}    # 変更点\n",
        "dim: 768\n",
        "emb_dropout: 0.0\n",
        "lora: true\n",
        "r: 8\n",
        "lora_alpha: 32\n",
        "lora_dropout: 0.01\n",
        "target_modules: [q_proj, v_proj]\n",
        "threshold: 0.5\n",
        "text_encoder: null\n",
        "pick_place_model: pick_place_convdecoder\n",
        "fusion_model: concat_transformer\n",
        "depth: 8\n",
        "heads: 16\n",
        "mlp_ratio: 4\n",
        "dropout: 0.0\n",
        "context_length: ${train_dataset.max_context_length}\n",
        "use_pos_embed: false\n",
        "text_max_length: 64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nf4S52J1PynN",
        "outputId": "7dc6d349-13ad-4c24-bc7e-fc670ee21d9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/bifold/bifold/conf/model/siglip_sequential.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZFz0yskStd2",
        "outputId": "888f3374-fe1e-4f61-c13f-dff7e51634bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/bifold\n",
            "/content/drive/MyDrive/東大松尾研究室/7_Thursday_WM_世界モデル/最終課題研究/tsuboi/results_v2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from WANDB_API_KEY.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchem-tsuboi\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m setting up run o48s6pbb (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m setting up run o48s6pbb (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m setting up run o48s6pbb (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.24.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/東大松尾研究室/7_Thursday_WM_世界モデル/最終課題研究/tsuboi/results_v2/wandb/run-20260214_113514-o48s6pbb\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msmoldering-infatuation-9\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/kazuma_tsuboi/WM_Final_v2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/kazuma_tsuboi/WM_Final_v2/runs/o48s6pbb\u001b[0m\n",
            "[2026-02-14 11:35:17,927][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 11:35:17,958][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/config.json \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 11:35:17,989][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/config.json \"HTTP/1.1 200 OK\"\n",
            "config.json: 100% 253/253 [00:00<00:00, 964kB/s]\n",
            "[2026-02-14 11:35:18,036][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/adapter_config.json \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 11:35:18,133][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 11:35:18,193][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/config.json \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 11:35:18,241][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/model.safetensors \"HTTP/1.1 302 Found\"\n",
            "[2026-02-14 11:35:18,336][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/google/siglip2-base-patch16-224/xet-read-token/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2 \"HTTP/1.1 200 OK\"\n",
            "model.safetensors: 100% 1.50G/1.50G [00:02<00:00, 628MB/s]\n",
            "Loading weights: 100% 408/408 [00:00<00:00, 829.88it/s, Materializing param=vision_model.post_layernorm.weight]\n",
            "trainable params: 589824 || all params: 375777794 || trainable%: 0.156960844791164\n",
            "[2026-02-14 11:35:25,284][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/processor_config.json \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 11:35:25,330][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/preprocessor_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 11:35:25,361][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/preprocessor_config.json \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 11:35:25,393][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/preprocessor_config.json \"HTTP/1.1 200 OK\"\n",
            "preprocessor_config.json: 100% 394/394 [00:00<00:00, 1.31MB/s]\n",
            "[2026-02-14 11:35:25,440][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/processor_config.json \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 11:35:25,479][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/preprocessor_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 11:35:25,510][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/preprocessor_config.json \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 11:35:25,555][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/google/siglip2-base-patch16-224/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 11:35:25,596][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/processor_config.json \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 11:35:25,638][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/chat_template.json \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 11:35:25,686][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/chat_template.jinja \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 11:35:25,730][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/audio_tokenizer_config.json \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 11:35:25,786][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/processor_config.json \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 11:35:25,828][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/preprocessor_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 11:35:25,844][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/preprocessor_config.json \"HTTP/1.1 200 OK\"\n",
            "The image processor of type `SiglipImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. \n",
            "[2026-02-14 11:35:25,890][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/processor_config.json \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 11:35:25,933][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/preprocessor_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 11:35:25,948][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/preprocessor_config.json \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 11:35:25,989][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 11:35:26,015][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/config.json \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 11:35:26,058][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 11:35:26,089][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 11:35:26,119][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
            "tokenizer_config.json: 47.2kB [00:00, 71.1MB/s]\n",
            "[2026-02-14 11:35:26,165][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 11:35:26,196][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 11:35:26,242][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/google/siglip2-base-patch16-224/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 11:35:26,294][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/google/siglip2-base-patch16-224/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 11:35:26,360][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/tokenizer.json \"HTTP/1.1 302 Found\"\n",
            "tokenizer.json: 100% 34.4M/34.4M [00:00<00:00, 65.4MB/s]\n",
            "[2026-02-14 11:35:26,939][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/tokenizer.model \"HTTP/1.1 302 Found\"\n",
            "tokenizer.model: 100% 4.24M/4.24M [00:00<00:00, 21.3MB/s]\n",
            "[2026-02-14 11:35:27,192][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/added_tokens.json \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 11:35:27,232][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/special_tokens_map.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 11:35:27,264][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/special_tokens_map.json \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 11:35:27,293][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/special_tokens_map.json \"HTTP/1.1 200 OK\"\n",
            "special_tokens_map.json: 100% 636/636 [00:00<00:00, 2.36MB/s]\n",
            "[2026-02-14 11:35:30,487][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/google/siglip2-base-patch16-224 \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 11:35:35,676][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/processor_config.json \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 11:35:35,717][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/preprocessor_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 11:35:35,732][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/preprocessor_config.json \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 11:35:35,775][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/processor_config.json \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 11:35:35,825][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/preprocessor_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 11:35:35,841][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/preprocessor_config.json \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 11:35:35,883][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/google/siglip2-base-patch16-224/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 11:35:35,924][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/processor_config.json \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 11:35:35,967][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/chat_template.json \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 11:35:36,008][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/chat_template.jinja \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 11:35:36,051][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/audio_tokenizer_config.json \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 11:35:36,095][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/processor_config.json \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 11:35:36,137][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/preprocessor_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 11:35:36,152][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/preprocessor_config.json \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 11:35:36,198][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/processor_config.json \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 11:35:36,238][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/preprocessor_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 11:35:36,252][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/preprocessor_config.json \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 11:35:36,294][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 11:35:36,308][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/config.json \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 11:35:36,350][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 11:35:36,364][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 11:35:36,411][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 11:35:36,426][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 11:35:36,471][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/google/siglip2-base-patch16-224/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 11:35:36,518][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/google/siglip2-base-patch16-224/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 11:35:40,013][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/google/siglip2-base-patch16-224 \"HTTP/1.1 200 OK\"\n",
            "Loaded model from checkpoint checkpoints/best.pth\n",
            "Error executing job with overrides: []\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bifold/bifold/__main__.py\", line 37, in main\n",
            "    trainer.eval()\n",
            "  File \"/content/bifold/bifold/__main__.py\", line 88, in eval\n",
            "    _, metric_dict = self.eval_epoch()\n",
            "                     ^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bifold/bifold/__main__.py\", line 178, in eval_epoch\n",
            "    metric_dict = self.eval_epoch_softgym_single(epoch)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bifold/bifold/__main__.py\", line 244, in eval_epoch_softgym_single\n",
            "    from .env.softgym_evaluator import SoftgymSingleEvaluator\n",
            "  File \"/content/bifold/bifold/env/softgym_evaluator.py\", line 6, in <module>\n",
            "    import pyflex\n",
            "ModuleNotFoundError: No module named 'pyflex'\n",
            "\n",
            "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33msmoldering-infatuation-9\u001b[0m at: \u001b[34mhttps://wandb.ai/kazuma_tsuboi/WM_Final_v2/runs/o48s6pbb\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20260214_113514-o48s6pbb/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%cd /content/bifold\n",
        "!python -m bifold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xepYlbVVmH3",
        "outputId": "2eb721a4-86b2-4437-afe8-06597faf5229"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/bifold\n",
            "/content/drive/MyDrive/東大松尾研究室/7_Thursday_WM_世界モデル/最終課題研究/tsuboi/results_v2\n",
            "[2026-02-14 12:45:29,113][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 12:45:29,154][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/config.json \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 12:45:29,238][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 12:45:29,278][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/config.json \"HTTP/1.1 200 OK\"\n",
            "Loading weights: 100% 408/408 [00:00<00:00, 479.24it/s, Materializing param=vision_model.post_layernorm.weight]\n",
            "trainable params: 589824 || all params: 375777794 || trainable%: 0.156960844791164\n",
            "[2026-02-14 12:45:38,763][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/processor_config.json \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 12:45:38,816][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/preprocessor_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 12:45:38,855][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/preprocessor_config.json \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 12:45:38,903][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/processor_config.json \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 12:45:38,954][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/preprocessor_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 12:45:38,970][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/preprocessor_config.json \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 12:45:39,027][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/google/siglip2-base-patch16-224/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 12:45:39,077][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/processor_config.json \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 12:45:39,128][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/chat_template.json \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 12:45:39,179][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/chat_template.jinja \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 12:45:39,243][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/audio_tokenizer_config.json \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 12:45:39,296][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/processor_config.json \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 12:45:39,345][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/preprocessor_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 12:45:39,361][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/preprocessor_config.json \"HTTP/1.1 200 OK\"\n",
            "The image processor of type `SiglipImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. \n",
            "[2026-02-14 12:45:39,419][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/processor_config.json \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 12:45:39,470][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/preprocessor_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 12:45:39,485][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/preprocessor_config.json \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 12:45:39,536][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 12:45:39,552][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/config.json \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 12:45:39,601][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 12:45:39,640][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 12:45:39,694][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/google/siglip2-base-patch16-224/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "[2026-02-14 12:45:39,710][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/siglip2-base-patch16-224/75de2d55ec2d0b4efc50b3e9ad70dba96a7b2fa2/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 12:45:39,763][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/google/siglip2-base-patch16-224/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
            "[2026-02-14 12:45:39,817][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/google/siglip2-base-patch16-224/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
            "[2026-02-14 12:45:43,285][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/google/siglip2-base-patch16-224 \"HTTP/1.1 200 OK\"\n",
            "Loaded model from checkpoint checkpoints/best.pth\n",
            "kp_mse:\t0.20\n",
            "ap_5:\t98.61\n",
            "ap_10:\t100.00\n",
            "ap_20:\t100.00\n",
            "ap_50:\t100.00\n",
            "iou:\tnan\n",
            "quantile_prob:\t99.98\n"
          ]
        }
      ],
      "source": [
        "%cd /content/bifold\n",
        "!python -m bifold eval_only=true simulator=null #lossだけ確認"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}